{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab84af78",
   "metadata": {},
   "source": [
    "### In this file, we will be using the processed data to create functions and output the final ChatBot.\n",
    "\n",
    "### Import Modules and Data\n",
    "First up, we will import the \"paragraphs.csv\" dataset which we created in the Text Analysis file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8169a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7d007c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify pdf path for later use\n",
    "pdf_path = 'deposit-account-agreement.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "584740f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our data\n",
    "paragraphs_df = pd.read_csv(\"paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "175e1aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Page</th>\n",
       "      <th>Formatted_content</th>\n",
       "      <th>Processed_content</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Effective 10/15/2023Deposit Account Agreement</td>\n",
       "      <td>Effective 10/15/2023Deposit Account Agreement</td>\n",
       "      <td>['2023deposit account agreement', 'account agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>This agreement is the contract that governs yo...</td>\n",
       "      <td>agreement contract governs account . Whether p...</td>\n",
       "      <td>['agreement jpmorgan chase', 'basic agreement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>signing a signature card or submitting an acco...</td>\n",
       "      <td>signing signature card submitting account appl...</td>\n",
       "      <td>['agreement applicable chase', 'chase agreemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>fees, and (4) other disclosures, agreements, a...</td>\n",
       "      <td>fee , ( 4 ) disclosure , agreement , amendment...</td>\n",
       "      <td>['fee apply account', 'fee disclosure agreemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Here are some important terms that we use thro...</td>\n",
       "      <td>important term use throughout agreement : Acco...</td>\n",
       "      <td>['account covered agreement', 'agreement accou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Page                                  Formatted_content  \\\n",
       "0           0     5      Effective 10/15/2023Deposit Account Agreement   \n",
       "1           1     5  This agreement is the contract that governs yo...   \n",
       "2           2     5  signing a signature card or submitting an acco...   \n",
       "3           3     5  fees, and (4) other disclosures, agreements, a...   \n",
       "4           4     5  Here are some important terms that we use thro...   \n",
       "\n",
       "                                   Processed_content  \\\n",
       "0      Effective 10/15/2023Deposit Account Agreement   \n",
       "1  agreement contract governs account . Whether p...   \n",
       "2  signing signature card submitting account appl...   \n",
       "3  fee , ( 4 ) disclosure , agreement , amendment...   \n",
       "4  important term use throughout agreement : Acco...   \n",
       "\n",
       "                                            keywords  \n",
       "0  ['2023deposit account agreement', 'account agr...  \n",
       "1  ['agreement jpmorgan chase', 'basic agreement ...  \n",
       "2  ['agreement applicable chase', 'chase agreemen...  \n",
       "3  ['fee apply account', 'fee disclosure agreemen...  \n",
       "4  ['account covered agreement', 'agreement accou...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick look at data\n",
    "paragraphs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcf63a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted column\n",
    "paragraphs_df = paragraphs_df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cc9151d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Formatted_content</th>\n",
       "      <th>Processed_content</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Effective 10/15/2023Deposit Account Agreement</td>\n",
       "      <td>Effective 10/15/2023Deposit Account Agreement</td>\n",
       "      <td>['2023deposit account agreement', 'account agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>This agreement is the contract that governs yo...</td>\n",
       "      <td>agreement contract governs account . Whether p...</td>\n",
       "      <td>['agreement jpmorgan chase', 'basic agreement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>signing a signature card or submitting an acco...</td>\n",
       "      <td>signing signature card submitting account appl...</td>\n",
       "      <td>['agreement applicable chase', 'chase agreemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>fees, and (4) other disclosures, agreements, a...</td>\n",
       "      <td>fee , ( 4 ) disclosure , agreement , amendment...</td>\n",
       "      <td>['fee apply account', 'fee disclosure agreemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Here are some important terms that we use thro...</td>\n",
       "      <td>important term use throughout agreement : Acco...</td>\n",
       "      <td>['account covered agreement', 'agreement accou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Page                                  Formatted_content  \\\n",
       "0     5      Effective 10/15/2023Deposit Account Agreement   \n",
       "1     5  This agreement is the contract that governs yo...   \n",
       "2     5  signing a signature card or submitting an acco...   \n",
       "3     5  fees, and (4) other disclosures, agreements, a...   \n",
       "4     5  Here are some important terms that we use thro...   \n",
       "\n",
       "                                   Processed_content  \\\n",
       "0      Effective 10/15/2023Deposit Account Agreement   \n",
       "1  agreement contract governs account . Whether p...   \n",
       "2  signing signature card submitting account appl...   \n",
       "3  fee , ( 4 ) disclosure , agreement , amendment...   \n",
       "4  important term use throughout agreement : Acco...   \n",
       "\n",
       "                                            keywords  \n",
       "0  ['2023deposit account agreement', 'account agr...  \n",
       "1  ['agreement jpmorgan chase', 'basic agreement ...  \n",
       "2  ['agreement applicable chase', 'chase agreemen...  \n",
       "3  ['fee apply account', 'fee disclosure agreemen...  \n",
       "4  ['account covered agreement', 'agreement accou...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take another look at df\n",
    "paragraphs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4abab3",
   "metadata": {},
   "source": [
    "Looks like we are good to go! Let's create all the algorithms and functions we will require to make the chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aac3c2",
   "metadata": {},
   "source": [
    "# All functions required\n",
    "\n",
    "### Function to get keywords from query\n",
    "Just like we had the function that extracts keywords from the data file, we will have a function that gets keywords from the user's query using the same keybert library.\n",
    "\n",
    "The only difference is, we will be chaning the parameters in the model to get a lower number of keywords as text in query will be much less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09d21922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keybert\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3539800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare model\n",
    "kw_model = KeyBERT(model='all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74823bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get keywords using model\n",
    "def getKeywordsOfQuery(s):\n",
    "    keywords = kw_model.extract_keywords(s, \n",
    "\n",
    "                                     keyphrase_ngram_range=(1, 3), \n",
    "\n",
    "                                     stop_words='english', \n",
    "\n",
    "                                     highlight=False,\n",
    "\n",
    "                                     top_n=3)\n",
    "\n",
    "    keywords_list= list(dict(keywords).keys())\n",
    "    return keywords_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe35d4c",
   "metadata": {},
   "source": [
    "### Function to remove stopwords and lemmatize query\n",
    "Keep in mind, we also need to remove stopwords and lemmatize query like we did for the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "54ca2eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6ecc18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "76497b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to lemmatize and remove stopwords\n",
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.lower() not in stop_words]\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec0162a",
   "metadata": {},
   "source": [
    "### Text highlight function\n",
    "This function will not be used for the chatbot itself, but to get an extra output of a file that has highlighted text from the source document, relating to the query the user is asking.\n",
    "\n",
    "This will be useful when the format of the output in the chatbot is not clear enough, or the user wants more information about the topic they asked the question on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f9f2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import fitz  # PyMuPDF\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5e425",
   "metadata": {},
   "source": [
    "Here's a quick rundown on what this function does:\n",
    "\n",
    "1. The most important text to highlight is the first keyword generated from the paragraph, as it has the most significance.\n",
    "2. If this keyword is not found in page, then highlight the SECOND keyword as it has the next most significance.\n",
    "3. We will get ALL the instances of text (or keyword) that we want to highlight in our specific page.\n",
    "4. We will then highlight all the instances\n",
    "5. Lastly, we will save the highlighted PDF as \"highlighted_\" + original name of pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "68cb215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def highlight_texts_in_pdf(pdf_path, page_number, texts_to_highlight):    \n",
    "    #get document\n",
    "    doc = fitz.open(pdf_path)   \n",
    "    \n",
    "\n",
    "    #get specific page\n",
    "    page = doc[page_number-1]\n",
    "    #list for instances\n",
    "    multi_instances=[]\n",
    "    \n",
    "    ##Finding the words in pdf\n",
    "    text_instances = page.search_for(texts_to_highlight[0])\n",
    "    if not text_instances:\n",
    "        #if first keyword is not there in page, then use second keyword\n",
    "        text_instances = page.search_for(texts_to_highlight[1])\n",
    "    #add instance to list    \n",
    "    multi_instances.append(text_instances)\n",
    "    ### HIGHLIGHT\n",
    "    for instance in multi_instances:\n",
    "        for inst in instance:\n",
    "            #highlight\n",
    "            highlight = page.add_highlight_annot(inst)\n",
    "    \n",
    "    #output file name and save\n",
    "    output = \"Highlighted_\"+pdf_path\n",
    "    doc.save(output, garbage=4, deflate=True, clean=False)\n",
    "    #return name of output file\n",
    "    return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1677f",
   "metadata": {},
   "source": [
    "### Functions to match keywords from query to keywords of document and print results\n",
    "\n",
    "We have the user's query with keywords and paragraphs from the data file with keywords.\n",
    "\n",
    "We need to match the user's query to paragraphs from data file using an algorithm. We cannot just show every paragraph that has one of the keywords from the query. If one of the keywords from the query was \"bank\", then we would end up displaying almost every paragraph in the document! \n",
    "\n",
    "The solution I created for this is: \n",
    "1. create a function count_match that gives the \"score\" of a query for a single paragraph(or row). This score will be the number of keywords from the query which were also present in the keywords of that row.\n",
    "2. A function match_with_query that takes in the \"maxcount\" or the maximum score attained by the query using the previous function. \n",
    "3. This function match_with_query then checks which paragraph(s) atatined this maximum score and appends all those paragraphs to the final result text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "181c3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to count number of query keywords found in row keywords\n",
    "#takes in query's keyword list and one row at a time\n",
    "def count_match(qlist, row):\n",
    "    count=0\n",
    "    for q in qlist:\n",
    "        if q in row.keywords:\n",
    "            count+=1\n",
    "    return count\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7844408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to match paragraphs with query using maxcount.\n",
    "#maxcount is obtained in the query_results function\n",
    "def match_with_query(qlist, maxcount, row):\n",
    "    count=0\n",
    "    matchlist=[]\n",
    "    result_text=\"\"\n",
    "    #check count of the row again (similar to previous function)\n",
    "    for q in qlist:\n",
    "        if q in row.keywords:\n",
    "            count+=1\n",
    "            #append keyword found to matchlist\n",
    "            matchlist.append(q)\n",
    "            \n",
    "    # check if count matches maxcount, if yes then add content to result text\n",
    "    if count==maxcount:\n",
    "        result_text += \"\\n\" + row['Formatted_content'] + \"\\n\"\n",
    "        result_text += f\"Content found in Page {row['Page']} of document {pdf_path}\\n\"\n",
    "        #call highlight function if matchlist has any keywords in it\n",
    "        if  len(matchlist)>0:    \n",
    "            highlighted_pdf_path = highlight_texts_in_pdf(pdf_path, row['Page'], matchlist)\n",
    "    \n",
    "    #return the final text\n",
    "    return result_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01909ea6",
   "metadata": {},
   "source": [
    "### Final function to integrate all:\n",
    "This is the final function that will be called by the gradio chatbot. This function needs to integrate all the functions we have created so far. Here's a step by step process of what happens in this \"query_results\" funciton:\n",
    "1. We first call the preprocess_text function on the query.\n",
    "2. We then get a list of keywords from the processed query using the getKeywordsOfQuery function\n",
    "3. We then get the count (or score) of each row in the dataframe against the query list and store all these scores in a list\n",
    "4. We get the maximum count (or score) from the list\n",
    "5. We call the match_with_query function, and get the resulting paragraph texts.\n",
    "6. We append the resulting texts and additional text we want the chatbot to display all into one result\n",
    "7. We return this result to the chatbot, for it to display!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "abd07cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_results(query, history):\n",
    "    #preprocess the query\n",
    "    query=preprocess_text(query)\n",
    "    #get keyword list of query\n",
    "    qlist=getKeywordsOfQuery(query)\n",
    "    #get keyword count for all rows\n",
    "    l=list(paragraphs_df.apply(partial(count_match, qlist), axis=1))\n",
    "    #get max count value\n",
    "    maxcount=max(l)\n",
    "    #get result texts from the data into a list\n",
    "    result_list=list(paragraphs_df.apply(partial(match_with_query, qlist, maxcount),axis=1))\n",
    "    \n",
    "    #append all text, including result list, into one text variable result\n",
    "    result = \"Here's what I could gather from the bank documents...\"\n",
    "    result += \"\\n\".join(result_list) #convert list to string\n",
    "    result+= \"\\n \" + f\"Highlighted PDF saved at: highlighted_{pdf_path}\"\n",
    "    result+= \"\\n can I answer any more questions?\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0dd5f",
   "metadata": {},
   "source": [
    "## Set up gradio link\n",
    "To wrap the whole thing up, we will call the gradio chatbot for our function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c7fb4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8c249a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7885\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7885/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call chatbot for our function\n",
    "iface = gr.ChatInterface(query_results)\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
